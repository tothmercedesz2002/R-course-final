---
title: "Analysis of Animal Rescues (tidytuesday)"
author: "T√≥th Merc√©desz"
output:
  html_document:
    toc: true
    toc_depth: 1
    toc_float: true
editor_options: 
  chunk_output_type: console
---
# üêæ About the dataset üêæ

The dataset includes data about the London Fire Brigade's **animal rescues** since **January 2009**. As provided in the official dataset description, in **2020**, there was a **20% increase** in rescues compared to 2019. The biggest increase was observed among **non-domestic animals**.

Codebook available [here.](https://github.com/rfordatascience/tidytuesday/blob/main/data/2021/2021-06-29/readme.md)

# üêæ Goals of this analysis üêæ

In this analysis, I will:  
- prepare the dataset, compute variables and visualize them;  
- confirm the rise in rescues by plotting (also comparing domestic and wild animals);  
- look for correlations between variables of interest;  
- investigate whether non-domestic animals' rescue costs more money than domestic animals' rescue by fitting a linear regression model;  
- investigate what other factors influence rescue cost with a more complex linear regression model;  
- compare the simple and the more complex models' performance.

In both models, the **outcome** variable will be incident_notional_cost.

In the more complex model, I will include the following **predictors**:  
- day_or_night: computed from date_time_of_call (0: day, 1: night);  
- pump_count: number of trucks needed for the rescue;    
- pump_hours_total: length of rescue operation;  
- domestic_wild: computed from animal_group_parent (0: domestic; 1: wild);  
- borough_inner_outer: computed from borough based on [Wikipedia](https://en.wikipedia.org/wiki/London_boroughs) (0: inner; 1: outer).

See the whole repository made for this project [here.](https://github.com/tothmercedesz2002/R-course-final)

![*Photo by Scott Walsh on Unsplash*](https://images.unsplash.com/photo-1500479694472-551d1fb6258d?q=80&w=2070&auto=format&fit=crop&ixlib=rb-4.0.3&ixid=M3wxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8fA%3D%3D)

# üêæ Setup üêæ

## Loading packages

```{r message = FALSE, warning = FALSE}
library(tidyverse)
library(skimr)
library(correlation)
library(performance)
library(broom)
library(car)
library(lmtest)
library(ggcorrplot)
library(lm.beta)
library(ggfortify)
library(lubridate)
```

## Reading the dataset

```{r}
animal_rescues_raw <- read_csv("https://raw.githubusercontent.com/rfordatascience/tidytuesday/main/data/2021/2021-06-29/animal_rescues.csv")
```

# üêæ Preparing the dataset, computing variables and visualizing them üêæ

## First look at the dataset, filtering data and converting variables

```{r}
# Checking structure and variables' type

str(animal_rescues_raw)

# Selecting variables of interest

animal_rescues_interest <- animal_rescues_raw %>%
  select(date_time_of_call, cal_year, pump_count, pump_hours_total, incident_notional_cost, animal_group_parent, borough)

# Looking for missing data

sum(is.na(animal_rescues_interest))
which(rowSums(is.na(animal_rescues_interest)) > 0)
missing_info <- animal_rescues_interest[c(4138, 4165, 4246, 4709, 5897, 6339, 6768, 7072, 7478), ]
print(missing_info)

unique(animal_rescues_interest$pump_count)
unique(animal_rescues_interest$pump_hours_total)
unique(animal_rescues_interest$incident_notional_cost)
unique(animal_rescues_interest$animal_group_parent)

# Filtering rows with missing values and "NULL" values

animal_rescues_interest <- animal_rescues_interest %>%
  filter(!is.na(borough)) %>%
  filter(pump_count != "NULL") %>%
  filter(pump_hours_total != "NULL") %>%
  filter(incident_notional_cost != "NULL")

# Converting variables

animal_rescues_interest <- animal_rescues_interest %>%
  mutate(
    date_time_of_call = dmy_hm(date_time_of_call),
    pump_count = as.numeric(pump_count),
    pump_hours_total = as.numeric(pump_hours_total),
    incident_notional_cost = as.numeric(incident_notional_cost),
    animal_group_parent = as.factor(animal_group_parent),
    borough = as.factor(borough)
    )

str(animal_rescues_interest)
summary(animal_rescues_interest)
```

## Computing day_or_night variable and visualization

```{r}
# Computing day_or_night variable
# 0 - day: 06:00 - 18:00
# 1 - night: 18:01 - 05:59

animal_rescues_interest <- animal_rescues_interest %>%
  mutate(
    day_or_night = case_when(
      hour(date_time_of_call) >= 6 & hour(date_time_of_call) < 18 ~ 0,
      TRUE ~ 1)
  )

# Creating an extra variable for plotting

animal_rescues_interest <- animal_rescues_interest %>%
  mutate(
    day_or_night_forplots = factor(
      day_or_night,
      levels = c(0, 1),
      labels = c("Day", "Night"))
  )

# Checking and comparing counts of day and night animal rescues

ggplot(animal_rescues_interest, aes(day_or_night_forplots, fill = day_or_night_forplots)) +
  geom_bar() +
  labs(
    x = "Time of day",
    y = "Number of rescues",
    title = "Animal rescues by time of day"
  ) +
  scale_fill_manual(values = c("Day" = "#cc5500", "Night" = "#000080")) +
  theme_minimal() +
  theme(legend.position = "none", plot.title = element_text(hjust = 0.5))
```

## Computing domestic_wild variable and visualization

```{r}
# Computing domestic_wild variable
# 0: domestic (traditional pets and livestock)
# 1: wild (including exotic animals kept as pets)

levels(animal_rescues_interest$animal_group_parent)

animal_rescues_interest <- animal_rescues_interest %>%
  mutate(animal_group_parent = fct_recode(animal_group_parent, 
                                          "Cat" = "cat", 
                                          "Sheep" = "Lamb", 
                                          "Bird" = "Pigeon", 
                                          "Cow" = "Bull")) 
  
levels(animal_rescues_interest$animal_group_parent)

# Domestic: "Cow", "Hamster", "Horse", "Unknown - Animal rescue from water - Farm animal", "Unknown - Heavy Livestock Animal", "Cat", "Dog", "Goat", "Sheep", "Rabbit", "Unknown - Animal rescue from below ground - Farm animal", "Unknown - Domestic Animal Or Pet"

# Wild: "Bird", "Deer", "Ferret", "Hedgehog", "Fox", "Lizard", "Snake", "Tortoise", "Budgie", "Fish", "Hedgehog", "Squirrel", "Unknown - Wild Animal" 

animal_rescues_interest <- animal_rescues_interest %>%
  mutate(domestic_wild = ifelse(animal_group_parent %in% c(
    "Cow", "Hamster", "Horse", "Unknown - Animal rescue from water - Farm animal", 
    "Unknown - Heavy Livestock Animal", "Cat", "Dog", "Goat", "Sheep", "Rabbit", 
    "Unknown - Animal rescue from below ground - Farm animal", "Unknown - Domestic Animal Or Pet"
    ), 0, 1))

animal_rescues_interest <- animal_rescues_interest %>%
  mutate(domestic_wild = as.factor(domestic_wild))

# Creating an extra variable for plotting

animal_rescues_interest <- animal_rescues_interest %>%
  mutate(
    domestic_wild_forplots = factor(
      domestic_wild,
      levels = c(0, 1),
      labels = c("Domestic", "Wild"))
  )

# Checking and comparing counts of domestic and wild rescued animals

ggplot(animal_rescues_interest, aes(domestic_wild_forplots, fill = domestic_wild_forplots)) +
  geom_bar() +
  labs(
    x = "Type of animal",
    y = "Number of rescues",
    title = "Animal rescues by animal type"
  ) +
  scale_fill_manual(values = c("Domestic" = "pink", "Wild" = "purple")) +
  theme_minimal() +
  theme(legend.position = "none", plot.title = element_text(hjust = 0.5))
```

## Computing borough_inner_outer and visualization

```{r}
# Computing borough_inner_outer
# 0: inner
# 1: outer

levels(animal_rescues_interest$borough)

animal_rescues_interest <- animal_rescues_interest %>%
  mutate(borough = str_to_title(as.character(borough))) %>%
  mutate(borough = factor(borough))

levels(animal_rescues_interest$borough)

valid_boroughs <- c(
  "Barking and Dagenham", "Barnet", "Bexley", "Brent", "Bromley", "Camden", "Croydon", "Ealing",
  "Enfield", "Greenwich", "Hackney", "Hammersmith And Fulham", "Haringey", "Harrow", "Havering", 
  "Hillingdon", "Hounslow", "Islington", "Kensington And Chelsea", "Kingston upon Thames", 
  "Lambeth", "Lewisham", "Merton", "Newham", "Redbridge", "Richmond Upon Thames", "Southwark", 
  "Sutton", "Tower Hamlets", "Waltham Forest", "Wandsworth", "Westminster"
)

animal_rescues_interest <- animal_rescues_interest %>%
  filter(borough %in% valid_boroughs)
animal_rescues_interest$borough <- droplevels(animal_rescues_interest$borough)

levels(animal_rescues_interest$borough)
nlevels(animal_rescues_interest$borough)

# inner boroughs: "Camden", "Greenwich", "Hackney", "Hammersmith And Fulham", "Islington", "Kensington And Chelsea", "Lambeth", "Lewisham", "Southwark", "Tower Hamlets", "Wandsworth", "Westminster"

animal_rescues_interest <- animal_rescues_interest %>%
  mutate(borough_inner_outer = ifelse(borough %in% c(
    "Camden", "Greenwich", "Hackney", "Hammersmith And Fulham", "Islington", "Kensington And Chelsea", "Lambeth",
    "Lewisham", "Southwark", "Tower Hamlets", "Wandsworth", "Westminster"
    ), 0, 1))

animal_rescues_interest <- animal_rescues_interest %>%
  mutate(borough_inner_outer = as.factor(borough_inner_outer))

# Creating an extra variable for plotting

animal_rescues_interest <- animal_rescues_interest %>%
  mutate(
    borough_inner_outer_forplots = factor(
      borough_inner_outer,
      levels = c(0, 1),
      labels = c("Inner", "Outer"))
  )

# Checking and comparing counts of animal rescues in inner and outer boroughs of London

ggplot(animal_rescues_interest, aes(borough_inner_outer_forplots, fill = borough_inner_outer_forplots)) +
  geom_bar() +
  labs(
    x = "Type of borough",
    y = "Number of rescues",
    title = "Animal rescues in London boroughs"
  ) +
  scale_fill_manual(values = c("Inner" = "#50c878", "Outer" = "#db7093")) +
  theme_minimal() +
  theme(legend.position = "none", plot.title = element_text(hjust = 0.5))
```

## Exploring distribution of remaining variables of interest
```{r}
# pump_count

mean(animal_rescues_interest$pump_count)
sd(animal_rescues_interest$pump_count)
min(animal_rescues_interest$pump_count)
max(animal_rescues_interest$pump_count)

ggplot(animal_rescues_interest, aes(pump_count)) +
  geom_histogram(binwidth = 1, fill = "#e6e6fa", color = "black") +
  labs(
    x = "Number of pumps",
    y = "Count",
    title = "Distribution of pump count"
  ) +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5))

# Due to pump_count = 1 overwhelming the plot, here is another plot with pump_count > 1

ggplot(animal_rescues_interest %>% filter(pump_count > 1), aes(pump_count)) +
  geom_histogram(binwidth = 1, fill = "#e6e6fa", color = "black") +
  labs(
    x = "Number of pumps",
    y = "Count",
    title = "Distribution of pump count (> 1)"
  ) +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5))

# pump_hours_total

mean(animal_rescues_interest$pump_hours_total)
sd(animal_rescues_interest$pump_hours_total)
min(animal_rescues_interest$pump_hours_total)
max(animal_rescues_interest$pump_hours_total)

ggplot(animal_rescues_interest, aes(pump_hours_total)) +
  geom_histogram(binwidth = 1, fill = "#b0e0e6", color = "black") +
  labs(
    x = "Hours",
    y = "Count",
    title = "Distribution of rescue length"
  ) +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5))

# Due to low values overwhelming the plot, here is another plot with pump_hours_total > 3

ggplot(animal_rescues_interest %>% filter(pump_hours_total > 3), aes(pump_hours_total)) +
  geom_histogram(binwidth = 1, fill = "#b0e0e6", color = "black") +
  labs(
    x = "Hours",
    y = "Count",
    title = "Distribution of rescue length (> 3)"
  ) +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5))

# incident_notional_cost

mean(animal_rescues_interest$incident_notional_cost)
sd(animal_rescues_interest$incident_notional_cost)
min(animal_rescues_interest$incident_notional_cost)
max(animal_rescues_interest$incident_notional_cost)

ggplot(animal_rescues_interest, aes(incident_notional_cost)) +
  geom_histogram(binwidth = 100, fill = "#8fbc8f", color = "black") +
  labs(
    x = "Notional cost of rescues",
    y = "Count",
    title = "Distribution of notional cost of rescues"
  ) +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5))

# Due to low values overwhelming the plot, here is another plot with incident_notional_cost > 1000

ggplot(animal_rescues_interest %>% filter(incident_notional_cost > 1000), aes(incident_notional_cost)) +
  geom_histogram(binwidth = 100, fill = "#8fbc8f", color = "black") +
  labs(
    x = "Notional cost of rescues",
    y = "Count",
    title = "Distribution of notional cost of rescues (> 1000)"
  ) +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5))

# Since the cost of the rescue is the main focus of my analysis (I want to know what causes the extreme values), I will leave the variable as it is (no transformations).
```

# üêæ Confirming the rise in rescues by plotting üêæ

```{r}
# According to the dataset description, there was an increase in rescues in 2020, especially when it comes to wild animals. In this section, I will confirm this trend via plotting.

# Grouping by year and calculating the count of rescues per year

rescues_per_year <- animal_rescues_interest %>%
  group_by(cal_year, domestic_wild_forplots) %>%
  summarise(rescue_count = n())

# Plotting (both for domestic and wild animals)

ggplot(rescues_per_year, aes(x = cal_year, y = rescue_count)) +
  geom_line(color = "#ff69b4", size = 1) +
  geom_point() +
  scale_x_continuous(breaks = 2009:2021) +
  labs(
    x = "Year",
    y = "Number of rescues",
    title = "Number of rescues per year"
  ) +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5))

# Plotting (separate lines for domestic and wild animals)

ggplot(rescues_per_year, aes(
  x = cal_year, y = rescue_count, color = domestic_wild_forplots, group = domestic_wild_forplots)) +
  geom_line(size = 1) +
  geom_point() +
  scale_x_continuous(breaks = 2009:2021) +
  scale_color_manual(values = c("Domestic" = "pink", "Wild" = "purple")) +
  labs(
    x = "Year",
    y = "Number of Rescues",
    title = "Number of domestic and wild animal rescues per year",
    color = "Animal Type"
  ) +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5))

# Calculating increase

rescues_change_comparison <- rescues_per_year %>%
  filter(cal_year %in% c(2019, 2020)) %>%
  group_by(domestic_wild_forplots) %>%
  spread(key = cal_year, value = rescue_count) %>%
  mutate(increase = `2020` - `2019`) 

print(rescues_change_comparison)

# Conclusion: Indeed, in 2020 there was an increase in animal rescues, especially in wild animal rescues.
```

# üêæ Looking for correlations between variables of interest üêæ

```{r}
correlations <- animal_rescues_interest %>%
  select(incident_notional_cost, cal_year, pump_count, pump_hours_total, day_or_night, domestic_wild, borough_inner_outer) %>%
  mutate(
    day_or_night = as.numeric(day_or_night),
    domestic_wild = as.numeric(domestic_wild),
    borough_inner_outer = as.numeric(borough_inner_outer)) %>%
  correlation() %>%
  print()

ggcorrplot(correlations)

# The main focus is incident_notional_cost, the price of rescues.
# Weak positive correlation with cal_year: rescues became more expensive over time
# Strong positive correlation with pump_count: if more pumps are necessary, the rescue becomes more expensive
# Strong positive correlation with pump_hours_total: longer rescues are more expensive
# Weak negative correlation with day_or_night: night rescues are a bit cheaper (maybe due to less traffic?)
# No significant correlation with domestic_wild (but domestic animals are little bit more expensive)
# Weak positive correlation with borough_inner_outer: rescues in outer boroughs are slightly more expensive
```

## Checking for linear relationships

```{r}
ggplot(animal_rescues_interest, aes(cal_year, incident_notional_cost)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE) +
  theme_minimal()

ggplot(animal_rescues_interest, aes(pump_count, incident_notional_cost)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE) +
  theme_minimal()

ggplot(animal_rescues_interest, aes(pump_hours_total, incident_notional_cost)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE) +
  theme_minimal()
```

# üêæ Building null model - investigating whether non-domestic animals' rescue costs more money than domestic animals' rescue by fitting a linear regression modelüêæ

```{r}
nullmodel <- lm(incident_notional_cost ~ domestic_wild, data = animal_rescues_interest)

# Model statistics
glance(nullmodel)

#Coefficients
summary(nullmodel)
tidy(nullmodel, conf.int = TRUE)

# Computing standardized beta coefficients
nullmodel_standardized <- lm.beta(nullmodel)
coef(nullmodel_standardized)
```

```{r}
# Extracting specific model test statistics
adjusted_r2_nullmodel <- glance(nullmodel) %>% pull(adj.r.squared)
f_statistic_nullmodel <- glance(nullmodel) %>% pull(statistic)
p_value_nullmodel <- glance(nullmodel) %>% pull(p.value)
df_nullmodel <- glance(nullmodel) %>% pull(df)
AIC_nullmodel <- glance(nullmodel) %>% pull(AIC)

model_stats_nullmodel <- tibble(
  Statistic = c("Adjusted R-squared", "F-statistic", "p-value", "Degrees of Freedom", "AIC"),
  Value = c(adjusted_r2_nullmodel, f_statistic_nullmodel, p_value_nullmodel, df_nullmodel, AIC_nullmodel))

print(model_stats_nullmodel)

# Extracting coefficients
standardized_coefficients_nullmodel <- (coef(nullmodel_standardized))[-1]
  
coeff_extracted_nullmodel <- tidy(nullmodel, conf.int = TRUE) %>%
  select(term, estimate, conf.low, conf.high, p.value) %>%
  mutate(standardized = c(NA, standardized_coefficients_nullmodel))

print(coeff_extracted_nullmodel)
```

```{r}
# Cook's distance for nullmodel and checking for influential outliers (Cook's distance > 1)
cooks_distance_nullmodel <- cooks.distance(nullmodel)
influential_outliers_nullmodel <- which(cooks_distance_nullmodel > 1)
influential_outliers_nullmodel

# Q-Q plot for normality check
autoplot(nullmodel, which = 2)

## Compute leverage values and checking leverage for specific observations that deviate from the Q-Q plot line
leverage_values <- hatvalues(nullmodel)
leverage_values[c(3541, 2399, 4201)]

## Viewing observations that might be influential
animal_rescues_interest[3541, ]
animal_rescues_interest[2399, ]
animal_rescues_interest[4201, ]
### Horses and a cat with high rescue costs.

# Residuals vs Fitted plot to check linearity and homoskedasticity
autoplot(nullmodel, which = 1)
```

## Null model with log transformed outcome variable
```{r}
# Due to assumption violations, I will try log transformation

animal_rescues_interest <- animal_rescues_interest %>%
  mutate(log_incident_notional_cost = log(incident_notional_cost + 1))

nullmodel_log <- lm(log_incident_notional_cost ~ domestic_wild, data = animal_rescues_interest)

# Model statistics
glance(nullmodel_log)

#Coefficients
summary(nullmodel_log)
tidy(nullmodel_log, conf.int = TRUE)

# Computing standardized beta coefficients
nullmodel_log_standardized <- lm.beta(nullmodel_log)
coef(nullmodel_log_standardized)
```

```{r}
# Extracting specific model test statistics
adjusted_r2_nullmodel_log <- glance(nullmodel_log) %>% pull(adj.r.squared)
f_statistic_nullmodel_log <- glance(nullmodel_log) %>% pull(statistic)
p_value_nullmodel_log <- glance(nullmodel_log) %>% pull(p.value)
df_nullmodel_log <- glance(nullmodel_log) %>% pull(df)
AIC_nullmodel_log <- glance(nullmodel_log) %>% pull(AIC)

model_stats_nullmodel_log <- tibble(
  Statistic = c("Adjusted R-squared", "F-statistic", "p-value", "Degrees of Freedom", "AIC"),
  Value = c(adjusted_r2_nullmodel_log, f_statistic_nullmodel_log, p_value_nullmodel_log, df_nullmodel_log, AIC_nullmodel_log))

print(model_stats_nullmodel_log)

# Extracting coefficients
standardized_coefficients_nullmodel_log <- (coef(nullmodel_log_standardized))[-1]
  
coeff_extracted_nullmodel_log <- tidy(nullmodel_log, conf.int = TRUE) %>%
  select(term, estimate, conf.low, conf.high, p.value) %>%
  mutate(standardized = c(NA, standardized_coefficients_nullmodel_log))

print(coeff_extracted_nullmodel_log)
```

```{r}
# Extracting specific model test statistics
adjusted_r2_nullmodel <- glance(nullmodel) %>% pull(adj.r.squared)
f_statistic_nullmodel <- glance(nullmodel) %>% pull(statistic)
p_value_nullmodel <- glance(nullmodel) %>% pull(p.value)
df_nullmodel <- glance(nullmodel) %>% pull(df)
AIC_nullmodel <- glance(nullmodel) %>% pull(AIC)

model_stats_nullmodel <- tibble(
  Statistic = c("Adjusted R-squared", "F-statistic", "p-value", "Degrees of Freedom", "AIC"),
  Value = c(adjusted_r2_nullmodel, f_statistic_nullmodel, p_value_nullmodel, df_nullmodel, AIC_nullmodel))

print(model_stats_nullmodel)

# Extracting coefficients
standardized_coefficients_nullmodel <- (coef(nullmodel_standardized))[-1]
  
coeff_extracted_nullmodel <- tidy(nullmodel, conf.int = TRUE) %>%
  select(term, estimate, conf.low, conf.high, p.value) %>%
  mutate(standardized = c(NA, standardized_coefficients_nullmodel))

print(coeff_extracted_nullmodel)
```

```{r}
# Cook's distance for nulllmodel_log and checking for influential outliers (Cook's distance > 1)
cooks_distance_nullmodel_log <- cooks.distance(nullmodel_log)
influential_outliers_nullmodel_log <- which(cooks_distance_nullmodel_log > 1)
influential_outliers_nullmodel_log

# Q-Q plot for normality check
autoplot(nullmodel_log, which = 2)

## Compute leverage values and checking leverage for specific observations that deviate from the Q-Q plot line
leverage_values <- hatvalues(nullmodel_log)
leverage_values[c(5518, 2399, 420)]

## Viewing observations that might be influential
animal_rescues_interest[5518, ]
animal_rescues_interest[2399, ]
animal_rescues_interest[4201, ]
### Horses and a dog with no rescue cost.

# Residuals vs Fitted plot to check linearity and homoskedasticity
autoplot(nullmodel_log, which = 1)

# The model didn't get much better when it comes to assumptions, so I will stick to no log-transformation for easier interpretation. I don't want to get rid of the high rescue costs because they are my main interest.
```

# üêæ Building complex model - investigate what other factors influence rescue cost with a more complex linear regression modelüêæ

In the more complex model, I will include the following **predictors**:  
- day_or_night: computed from date_time_of_call (0: day, 1: night);  
- pump_count: number of trucks needed for the rescue;    
- pump_hours_total: length of rescue operation;  
- domestic_wild: computed from animal_group_parent (0: domestic; 1: wild);  
- borough_inner_outer: computed from borough (0: inner; 1: outer).

```{r}
complexmodel <- lm(incident_notional_cost ~ day_or_night + pump_count + pump_hours_total + domestic_wild + borough_inner_outer, data = animal_rescues_interest)

# Model statistics
glance(complexmodel)

#Coefficients
summary(complexmodel)
tidy(complexmodel, conf.int = TRUE)

# Computing standardized beta coefficients
complexmodel_standardized <- lm.beta(complexmodel)
coef(complexmodel_standardized)
```

```{r}
# Extracting specific model test statistics
adjusted_r2_complexmodel <- glance(complexmodel) %>% pull(adj.r.squared)
f_statistic_complexmodel <- glance(complexmodel) %>% pull(statistic)
p_value_complexmodel <- glance(complexmodel) %>% pull(p.value)
df_complexmodel <- glance(complexmodel) %>% pull(df)
AIC_complexmodel <- glance(complexmodel) %>% pull(AIC)

model_stats_complexmodel <- tibble(
  Statistic = c("Adjusted R-squared", "F-statistic", "p-value", "Degrees of Freedom", "AIC"),
  Value = c(adjusted_r2_complexmodel, f_statistic_complexmodel, p_value_complexmodel, df_complexmodel, AIC_complexmodel))

print(model_stats_complexmodel)

# Extracting coefficients
standardized_coefficients_complexmodel <- (coef(complexmodel_standardized))[-1]
  
coeff_extracted_complexmodel <- tidy(complexmodel, conf.int = TRUE) %>%
  select(term, estimate, conf.low, conf.high, p.value) %>%
  mutate(standardized = c(NA, standardized_coefficients_complexmodel))

print(coeff_extracted_complexmodel)
```

```{r}
# Cook's distance for nulllmodel and checking for influential outliers (Cook's distance > 1)
cooks_distance_complexmodel <- cooks.distance(complexmodel)
influential_outliers_complexmodel <- which(cooks_distance_complexmodel > 1)
influential_outliers_complexmodel

# Q-Q plot for normality check
autoplot(complexmodel, which = 2)

## Compute leverage values and checking leverage for specific observations that deviate from the Q-Q plot line
leverage_values <- hatvalues(complexmodel)
leverage_values[c(1391, 6751, 4201)]

## Viewing observations that might be influential
animal_rescues_interest[1391, ]
animal_rescues_interest[6751, ]
animal_rescues_interest[4201, ]
### A horse, a deer and a cat with high rescue costs.

# Residuals vs Fitted plot to check linearity and homoskedasticity
autoplot(complexmodel, which = 1)

# Calculating VIF values for complex model
vif(complexmodel)
# vif < 5, so these are okay

# The assumption checks still don't look nice, so I will try the log-transformation again with the complex model too.
```

## Lets try log transforming again

```{r}
complexmodel_log <- lm(log_incident_notional_cost ~ day_or_night + pump_count + pump_hours_total + domestic_wild + borough_inner_outer, data = animal_rescues_interest)

# Model statistics
glance(complexmodel_log)

#Coefficients
summary(complexmodel_log)
tidy(complexmodel_log, conf.int = TRUE)

# Computing standardized beta coefficients
complexmodel_log_standardized <- lm.beta(complexmodel_log)
coef(complexmodel_log_standardized)
```

```{r}
# Extracting specific model test statistics
adjusted_r2_complexmodel_log <- glance(complexmodel_log) %>% pull(adj.r.squared)
f_statistic_complexmodel_log <- glance(complexmodel_log) %>% pull(statistic)
p_value_complexmodel_log <- glance(complexmodel) %>% pull(p.value)
df_complexmodel_log <- glance(complexmodel_log) %>% pull(df)
AIC_complexmodel_log <- glance(complexmodel_log) %>% pull(AIC)

model_stats_complexmodel_log <- tibble(
  Statistic = c("Adjusted R-squared", "F-statistic", "p-value", "Degrees of Freedom", "AIC"),
  Value = c(adjusted_r2_complexmodel_log, f_statistic_complexmodel_log, p_value_complexmodel_log, df_complexmodel_log, AIC_complexmodel_log))

print(model_stats_complexmodel_log)

# Extracting coefficients
standardized_coefficients_complexmodel_log <- (coef(complexmodel_log_standardized))[-1]
  
coeff_extracted_complexmodel_log <- tidy(complexmodel_log, conf.int = TRUE) %>%
  select(term, estimate, conf.low, conf.high, p.value) %>%
  mutate(standardized = c(NA, standardized_coefficients_complexmodel_log))

print(coeff_extracted_complexmodel_log)
```

```{r}
# Cook's distance for nulllmodel and checking for influential outliers (Cook's distance > 1)
cooks_distance_complexmodel_log <- cooks.distance(complexmodel_log)
influential_outliers_complexmodel_log <- which(cooks_distance_complexmodel_log > 1)
influential_outliers_complexmodel_log
# We have already seen these animals before, they had high rescue costs.

# Q-Q plot for normality check
autoplot(complexmodel_log, which = 2)

## Compute leverage values and checking leverage for specific observations that deviate from the Q-Q plot line
leverage_values <- hatvalues(complexmodel_log)
leverage_values[c(5518, 2399, 4201)]

## Viewing observations that might be influential
animal_rescues_interest[5518, ]
animal_rescues_interest[2399, ]
animal_rescues_interest[4201, ]
### High rescue costs or no cost.

# Residuals vs Fitted plot to check linearity and homoskedasticity
autoplot(complexmodel_log, which = 1)

# Calculating VIF values for complex model
vif(complexmodel_log)
# vif < 5, so these are okay

# Still not perfect (maybe somewhat nicer plots). I will compare both the original, both the log transformed models' performance.
```

üêæ Compare the simple and the more complex models' performance üêæ
```{r}
# These are the original models.

# Nullmodel stats
model_stats_nullmodel

# COmplex model stats
model_stats_complexmodel

# Comparing AIC values: the complex model has lower AIC (better)
AIC_nullmodel
AIC_complexmodel

# Comparing F values of the models: the complex model has higher F statistic (better)
f_statistic_nullmodel
f_statistic_complexmodel

# Comparing p values of the models: the complex model has lower p value (better)
p_value_nullmodel
p_value_complexmodel

# Coefficients
coeff_extracted_nullmodel
coeff_extracted_complexmodel

# In the null model, the animal type was not a significant predictor of rescue cost.
# In the more complex model:
## day_or_night: significant predicor (night rescues more expensive)
## pump_count: significant preditor (more pumps - less expensive)
## pump_hours_total: significant predictor (longer rescue - more expensive)
## domestic_wild: significant predictor (wild animals - more expensive)
## borough_inner_outer: not significant (outer borough - cheaper)

# Compared to the correlations, controlling for other factors as well, the picture became more detailed. For example, in the regression model, more pumps lead to smaller costs. That might be because the model also controls for the length of the rescue, which might be decreased if more pumps are working. Also, at night, maybe less pumps are available. In the regression, wild animal rescues and outer borough rescues were also associated with higher costs (the correlations were either weak or not significant in these cases).
```

```{r}
# These are the log transformed models

# Nullmodel stats
model_stats_nullmodel_log

# COmplex model stats
model_stats_complexmodel_log

# Comparing AIC values: the complex model has lower AIC (better)
# Both are better than the original models without log-transformation.
AIC_nullmodel_log
AIC_complexmodel_log

# Comparing F values of the models: the complex model has higher F statistic (better)
# The original complex model has higher F value
f_statistic_nullmodel_log
f_statistic_complexmodel_log

# Comparing p values of the models: the complex model has lower p value (better)
# Log-transformed nullmodel has lower p value than original, the complex models are both p = 0
p_value_nullmodel_log
p_value_complexmodel_log

# Coefficients
coeff_extracted_nullmodel_log
coeff_extracted_complexmodel_log

# In the null model, the animal type was not a significant predictor of rescue cost.
# In the more complex model:
## day_or_night: not significant
## pump_count: significant preditor (more pumps - less expensive)
## pump_hours_total: significant predictor (longer rescue - more expensive)
## domestic_wild: significant predictor (wild animals - more expensive)
## borough_inner_outer: not significant

# The coefficients' results are similar to the the results of the original models.
```