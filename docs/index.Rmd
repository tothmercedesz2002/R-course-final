---
title: "Analysis of Animal Rescues (tidytuesday)"
author: "T√≥th Merc√©desz"
output:
  html_document:
    toc: true
    toc_depth: 3
    toc_float: true
editor_options: 
  chunk_output_type: console
geometry: margin=1in
---

<style>
h1 {
  text-align: center;
  font-size: 22pt;
  line-height: 1.5;
}
.author {
  text-align: right;
  font-size: 20pt;
  line-height: 1.5;
}

body {
  text-align: justify;
  font-size: 12pt;
  line-height: 1.5;
}
h2 {
  text-align: left;
  font-size: 20px;
  line-height: 1.5;
}
}
h3 {
  text-align: left;
  font-size: 18pt;
  line-height: 1.5;
}
</style>

# üêæ About the dataset üêæ

The dataset includes data about the London Fire Brigade's **animal rescues** since **January 2009**. As provided in the official dataset description, in **2020**, there was a **20% increase** in rescues compared to 2019. The biggest increase was observed among **non-domestic animals**.

The **codebook** is available [here.](https://github.com/rfordatascience/tidytuesday/blob/main/data/2021/2021-06-29/readme.md)

# üêæ Goals of this analysis üêæ

In this analysis, I will:  
- prepare the dataset, compute variables and visualize them;  
- confirm the rise in rescues by plotting (also comparing domestic and wild animals);  
- look for relationships between variables of interest;  
- investigate whether non-domestic animals' rescue costs more money than domestic animals' rescue by fitting a linear regression model;  
- investigate what other factors influence rescue cost with a more complex linear regression model;  
- compare the simple and the more complex models' performance.

In both models, the **outcome** variable will be incident_notional_cost.  
My hypothesis is that **rescuing non-domestic animals is more expensive**.

In the more complex model, I will include the following **predictors**:  
- day_or_night: computed from date_time_of_call (0: day, 1: night);  
- pump_count: number of trucks needed for the rescue;    
- pump_hours_total: length of rescue operation;  
- domestic_wild: computed from animal_group_parent (0: domestic; 1: wild);  
- borough_inner_outer: computed from borough based on [Wikipedia](https://en.wikipedia.org/wiki/London_boroughs) (0: inner; 1: outer).

**See the whole repository made for this project [here.](https://github.com/tothmercedesz2002/R-course-final)**

![*Photo by Scott Walsh on Unsplash*](https://images.unsplash.com/photo-1500479694472-551d1fb6258d?q=80&w=2070&auto=format&fit=crop&ixlib=rb-4.0.3&ixid=M3wxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8fA%3D%3D)

# üêæ Setup üêæ

## Loading packages

```{r message = FALSE, warning = FALSE}
library(tidyverse)
library(skimr)
library(correlation)
library(performance)
library(broom)
library(car)
library(lmtest)
library(ggcorrplot)
library(lm.beta)
library(ggfortify)
library(lubridate)
```

## Reading the dataset

```{r}
animal_rescues_raw <- read_csv("https://raw.githubusercontent.com/rfordatascience/tidytuesday/main/data/2021/2021-06-29/animal_rescues.csv")
```

# üêæ Preparation and EDA üêæ

In this section, I am going to look at the dataset, select the variables that I would like to work with, look for missing values, and convert variables. Then, I am going to compute some variables. I will do exploratory data analysis as well via plotting.

## First look at the dataset, filtering data and converting variables

### Checking dataset's structure and variables' type

```{r}
str(animal_rescues_raw)
```

### Selecting variables of interest

```{r}
animal_rescues_interest <- animal_rescues_raw %>%
  select(date_time_of_call, cal_year, pump_count, pump_hours_total, incident_notional_cost, animal_group_parent, borough)
```

### Looking for missing data

```{r}
sum(is.na(animal_rescues_interest))
which(rowSums(is.na(animal_rescues_interest)) > 0)
missing_info <- animal_rescues_interest[c(4138, 4165, 4246, 4709, 5897, 6339, 6768, 7072, 7478), ]
print(missing_info)

unique(animal_rescues_interest$pump_count)
unique(animal_rescues_interest$pump_hours_total)
unique(animal_rescues_interest$incident_notional_cost)
unique(animal_rescues_interest$animal_group_parent)
```

### Filtering rows with missing values and "NULL" values

```{r}
animal_rescues_interest <- animal_rescues_interest %>%
  filter(!is.na(borough)) %>%
  filter(pump_count != "NULL") %>%
  filter(pump_hours_total != "NULL") %>%
  filter(incident_notional_cost != "NULL")
```

### Converting variables

```{r}
animal_rescues_interest <- animal_rescues_interest %>%
  mutate(
    date_time_of_call = dmy_hm(date_time_of_call),
    pump_count = as.numeric(pump_count),
    pump_hours_total = as.numeric(pump_hours_total),
    incident_notional_cost = as.numeric(incident_notional_cost),
    animal_group_parent = as.factor(animal_group_parent),
    borough = as.factor(borough)
    )

str(animal_rescues_interest)
summary(animal_rescues_interest)
```

## Computing day_or_night variable and visualization

### Computing day_or_night variable

0 - day: 06:00 - 18:00;  
1 - night: 18:01 - 05:59  

```{r}
animal_rescues_interest <- animal_rescues_interest %>%
  mutate(
    day_or_night = case_when(
      hour(date_time_of_call) >= 6 & hour(date_time_of_call) < 18 ~ 0,
      TRUE ~ 1)
  )
```

### Creating an extra variable for plotting

```{r}
animal_rescues_interest <- animal_rescues_interest %>%
  mutate(
    day_or_night_forplots = factor(
      day_or_night,
      levels = c(0, 1),
      labels = c("Day", "Night"))
  )
```

### Checking and comparing counts of day and night animal rescues via plotting

```{r}
ggplot(animal_rescues_interest, 
  aes(day_or_night_forplots, fill = day_or_night_forplots)) +
  geom_bar() +
  labs(
    x = "Time of day",
    y = "Number of rescues",
    title = "Animal rescues by time of day"
  ) +
  scale_fill_manual(values = c("Day" = "#cc5500", "Night" = "#000080")) +
  theme_minimal() +
  theme(legend.position = "none", plot.title = element_text(hjust = 0.5))
```

## Computing domestic_wild variable and visualization

### Computing domestic_wild variable

0: domestic (traditional pets and livestock);  
1: wild (including exotic animals kept as pets)  

```{r}
levels(animal_rescues_interest$animal_group_parent)

animal_rescues_interest <- animal_rescues_interest %>%
  mutate(animal_group_parent = fct_recode(animal_group_parent, 
                                          "Cat" = "cat", 
                                          "Sheep" = "Lamb", 
                                          "Bird" = "Pigeon", 
                                          "Cow" = "Bull")) 
  
levels(animal_rescues_interest$animal_group_parent)

# Domestic: "Cow", "Hamster", "Horse", "Unknown - Animal rescue from water - Farm animal", "Unknown - Heavy Livestock Animal", "Cat", "Dog", "Goat", "Sheep", "Rabbit", "Unknown - Animal rescue from below ground - Farm animal", "Unknown - Domestic Animal Or Pet"

# Wild: "Bird", "Deer", "Ferret", "Hedgehog", "Fox", "Lizard", "Snake", "Tortoise", "Budgie", "Fish", "Hedgehog", "Squirrel", "Unknown - Wild Animal" 

animal_rescues_interest <- animal_rescues_interest %>%
  mutate(domestic_wild = ifelse(animal_group_parent %in% c(
    "Cow", "Hamster", "Horse", "Unknown - Animal rescue from water - Farm animal", 
    "Unknown - Heavy Livestock Animal", "Cat", "Dog", "Goat", "Sheep", "Rabbit", 
    "Unknown - Animal rescue from below ground - Farm animal", "Unknown - Domestic Animal Or Pet"
    ), 0, 1))

animal_rescues_interest <- animal_rescues_interest %>%
  mutate(domestic_wild = as.factor(domestic_wild))
```

### Creating an extra variable for plotting

```{r}
animal_rescues_interest <- animal_rescues_interest %>%
  mutate(
    domestic_wild_forplots = factor(
      domestic_wild,
      levels = c(0, 1),
      labels = c("Domestic", "Wild"))
  )
```

### Checking and comparing counts of domestic and wild rescued animals via plotting

```{r}
ggplot(animal_rescues_interest, 
  aes(domestic_wild_forplots, fill = domestic_wild_forplots)) +
  geom_bar() +
  labs(
    x = "Type of animal",
    y = "Number of rescues",
    title = "Animal rescues by animal type"
  ) +
  scale_fill_manual(values = c("Domestic" = "pink", "Wild" = "purple")) +
  theme_minimal() +
  theme(legend.position = "none", plot.title = element_text(hjust = 0.5))
```

## Computing borough_inner_outer and visualization

### Computing borough_inner_outer

0: inner;  
1: outer  

```{r}
levels(animal_rescues_interest$borough)

animal_rescues_interest <- animal_rescues_interest %>%
  mutate(borough = str_to_title(as.character(borough))) %>%
  mutate(borough = factor(borough))

levels(animal_rescues_interest$borough)

valid_boroughs <- c(
  "Barking and Dagenham", "Barnet", "Bexley", "Brent", "Bromley", "Camden", "Croydon", "Ealing",
  "Enfield", "Greenwich", "Hackney", "Hammersmith And Fulham", "Haringey", "Harrow", "Havering", 
  "Hillingdon", "Hounslow", "Islington", "Kensington And Chelsea", "Kingston upon Thames", 
  "Lambeth", "Lewisham", "Merton", "Newham", "Redbridge", "Richmond Upon Thames", "Southwark", 
  "Sutton", "Tower Hamlets", "Waltham Forest", "Wandsworth", "Westminster"
)

animal_rescues_interest <- animal_rescues_interest %>%
  filter(borough %in% valid_boroughs)
animal_rescues_interest$borough <- droplevels(animal_rescues_interest$borough)

levels(animal_rescues_interest$borough)
nlevels(animal_rescues_interest$borough)

# inner boroughs: "Camden", "Greenwich", "Hackney", "Hammersmith And Fulham", "Islington", "Kensington And Chelsea", "Lambeth", "Lewisham", "Southwark", "Tower Hamlets", "Wandsworth", "Westminster"

animal_rescues_interest <- animal_rescues_interest %>%
  mutate(borough_inner_outer = ifelse(borough %in% c(
    "Camden", "Greenwich", "Hackney", "Hammersmith And Fulham", "Islington", "Kensington And Chelsea", "Lambeth",
    "Lewisham", "Southwark", "Tower Hamlets", "Wandsworth", "Westminster"
    ), 0, 1))

animal_rescues_interest <- animal_rescues_interest %>%
  mutate(borough_inner_outer = as.factor(borough_inner_outer))
```

### Creating an extra variable for plotting

```{r}
animal_rescues_interest <- animal_rescues_interest %>%
  mutate(
    borough_inner_outer_forplots = factor(
      borough_inner_outer,
      levels = c(0, 1),
      labels = c("Inner", "Outer"))
  )
```

### Checking and comparing counts of animal rescues in inner and outer boroughs of London via plotting

```{r}
ggplot(animal_rescues_interest, 
  aes(borough_inner_outer_forplots, fill = borough_inner_outer_forplots)) +
  geom_bar() +
  labs(
    x = "Type of borough",
    y = "Number of rescues",
    title = "Animal rescues in London boroughs"
  ) +
  scale_fill_manual(values = c("Inner" = "#50c878", "Outer" = "#db7093")) +
  theme_minimal() +
  theme(legend.position = "none", plot.title = element_text(hjust = 0.5))
```

## Exploring distribution of remaining variables of interest

### Exploring distribution of pump_count

```{r}
mean(animal_rescues_interest$pump_count)
sd(animal_rescues_interest$pump_count)
min(animal_rescues_interest$pump_count)
max(animal_rescues_interest$pump_count)

ggplot(animal_rescues_interest, aes(pump_count)) +
  geom_histogram(binwidth = 1, fill = "#800080") +
  labs(
    x = "Number of pumps",
    y = "Count",
    title = "Distribution of pump count"
  ) +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5))

# Due to pump_count = 1 overwhelming the plot, here is another plot with pump_count > 1

ggplot(animal_rescues_interest %>% filter(pump_count > 1), aes(pump_count)) +
  geom_histogram(binwidth = 1, fill = "#800080") +
  labs(
    x = "Number of pumps",
    y = "Count",
    title = "Distribution of pump count (> 1)"
  ) +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5))
```

### Exploring distribution of pump_hours_total

```{r}
mean(animal_rescues_interest$pump_hours_total)
sd(animal_rescues_interest$pump_hours_total)
min(animal_rescues_interest$pump_hours_total)
max(animal_rescues_interest$pump_hours_total)

ggplot(animal_rescues_interest, aes(pump_hours_total)) +
  geom_histogram(binwidth = 1, fill = "#b0e0e6") +
  labs(
    x = "Hours",
    y = "Count",
    title = "Distribution of rescue length"
  ) +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5))

# Due to low values overwhelming the plot, here is another plot with pump_hours_total > 3

ggplot(animal_rescues_interest %>% filter(pump_hours_total > 3), aes(pump_hours_total)) +
  geom_histogram(binwidth = 1, fill = "#b0e0e6") +
  labs(
    x = "Hours",
    y = "Count",
    title = "Distribution of rescue length (> 3)"
  ) +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5))
```

### Exploring distribution of incident_notional_cost

```{r}
mean(animal_rescues_interest$incident_notional_cost)
sd(animal_rescues_interest$incident_notional_cost)
min(animal_rescues_interest$incident_notional_cost)
max(animal_rescues_interest$incident_notional_cost)

ggplot(animal_rescues_interest, aes(incident_notional_cost)) +
  geom_histogram(binwidth = 100, fill = "#8fbc8f") +
  labs(
    x = "Notional cost of rescues",
    y = "Count",
    title = "Distribution of notional cost of rescues"
  ) +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5))

# Due to low values overwhelming the plot, here is another plot with incident_notional_cost > 1000

ggplot(animal_rescues_interest %>% filter(incident_notional_cost > 1000), aes(incident_notional_cost)) +
  geom_histogram(binwidth = 100, fill = "#8fbc8f") +
  labs(
    x = "Notional cost of rescues",
    y = "Count",
    title = "Distribution of notional cost of rescues (> 1000)"
  ) +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5))
```

Since the cost of the rescue is the main focus of my analysis (I want to know what causes the extreme values), I will not filter out the extreme values.

# üêæ Confirming the rise in rescues by plotting üêæ

According to the dataset description, there was an increase in rescues in 2020, especially when it comes to wild animals. In this section, I will confirm this trend via plotting.

## Grouping by year and calculating the count of rescues per year

```{r}
rescues_per_year <- animal_rescues_interest %>%
  group_by(cal_year, domestic_wild_forplots) %>%
  summarise(rescue_count = n())
```

## Plotting (both for domestic and wild animals)

```{r}
# Grouping by year and summarizing rescues
rescues_per_year_aggregated <- rescues_per_year %>%
  group_by(cal_year) %>%
  summarise(rescue_count = sum(rescue_count))

# Plotting
ggplot(rescues_per_year_aggregated, aes(cal_year, rescue_count, group = 1)) +
  geom_line(color = "#ff69b4", linewidth = 1) +
  geom_point() +
  scale_x_continuous(breaks = 2009:2021) +
  labs(
    x = "Year",
    y = "Number of rescues",
    title = "Number of rescues per year"
  ) +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5))
```

## Plotting (separate lines for domestic and wild animals)

```{r}
ggplot(rescues_per_year, 
  aes(cal_year, rescue_count, color = domestic_wild_forplots, group = domestic_wild_forplots)) +
  geom_line(linewidth = 1) +
  geom_point() +
  scale_x_continuous(breaks = 2009:2021) +
  scale_color_manual(values = c("Domestic" = "pink", "Wild" = "purple")) +
  labs(
    x = "Year",
    y = "Number of Rescues",
    title = "Number of domestic and wild animal rescues per year",
    color = "Animal Type"
  ) +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5))
```

### Calculating increase in domestic and wild animal rescues in 2020

```{r}
rescues_change_comparison <- rescues_per_year %>%
  filter(cal_year %in% c(2019, 2020)) %>%
  group_by(domestic_wild_forplots) %>%
  pivot_wider(names_from = cal_year, values_from = rescue_count) %>%
  mutate(increase = `2020` - `2019`) 

print(rescues_change_comparison)
```

Conclusion: Indeed, in 2020 there was an increase in animal rescues, especially in wild animal rescues.

# üêæ Relationships between variables of interest üêæ

## Checking correlations

```{r}
correlations <- animal_rescues_interest %>%
  select(incident_notional_cost, cal_year, pump_count, pump_hours_total, day_or_night, domestic_wild, borough_inner_outer) %>%
  mutate(
    day_or_night = as.numeric(day_or_night),
    domestic_wild = as.numeric(domestic_wild),
    borough_inner_outer = as.numeric(borough_inner_outer)) %>%
  correlation() %>%
  print()

ggcorrplot(correlations)
```

The main focus is incident_notional_cost, the price of rescues, so I will interpret the correlations concerning incident_notional_cost:

1. Weak positive correlation with cal_year: rescues became more expensive over time  
2. Strong positive correlation with pump_count: if more pumps are necessary, the rescue becomes more expensive  
3. Strong positive correlation with pump_hours_total: longer rescues are more expensive  
4. Weak negative correlation with day_or_night: night rescues are a bit cheaper (maybe due to less traffic?)  
5. No significant correlation with domestic_wild (but domestic animals are little bit more expensive)  
6. Weak positive correlation with borough_inner_outer: rescues in outer boroughs are slightly more expensive  

## Checking for differences

### Price differences according to animal type

```{r}
ggplot(animal_rescues_interest, aes(domestic_wild_forplots, incident_notional_cost)) +
  geom_point() +
  labs(
    x = "Animal type",
    y = "Incident notional cost",
    title = "Price differences according to animal type",
  ) +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5))
```

### Price differences according to day and night calls

```{r}
ggplot(animal_rescues_interest, aes(day_or_night_forplots, incident_notional_cost)) +
  geom_point() +
  labs(
    x = "Time of the day",
    y = "Incident notional cost",
    title = "Price differences according to day and night calls",
  ) +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5))
```

### Price differences according to boroughs

```{r}
ggplot(animal_rescues_interest, aes(borough_inner_outer_forplots, incident_notional_cost)) +
  geom_point() +
  labs(
    x = "Borough type",
    y = "Incident notional cost",
    title = "Price differences according to boroughs",
  ) +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5))
```

## Checking for linear relationships 

incident_notional_cost ~ other variables via plotting

### Relationship with cal_year

```{r}
ggplot(animal_rescues_interest, aes(cal_year, incident_notional_cost)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE) +
  labs(
    x = "Year",
    y = "Incident notional cost",
    title = "Relationship between year and rescue price",
  ) +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5))
```

### Relationship with pump_count

```{r}
ggplot(animal_rescues_interest, aes(pump_count, incident_notional_cost)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE) +
  labs(
    x = "Pump count",
    y = "Incident notional cost",
    title = "Relationship between pump count and rescue price",
  ) +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5))
```

### Relationship with pump_hours_total 

```{r}
ggplot(animal_rescues_interest, aes(pump_hours_total, incident_notional_cost)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE) +
  labs(
    x = "Rescue length",
    y = "Incident notional cost",
    title = "Relationship between year and pump_hours_total",
  ) +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5))
```

# üêæ Building null model üêæ

In this section I am going to investigating whether non-domestic animals' rescue costs more money than domestic animals' rescue by fitting a linear regression model.

Outcome variable: incident_notional_cost;  
Predictor: domestic_wild  

## Fitting null model

```{r}
nullmodel <- lm(incident_notional_cost ~ domestic_wild, data = animal_rescues_interest)
```

## Extracting statistics and coefficients of null model, computing standardized coefficients

```{r}
# Model statistics
glance(nullmodel)

# Extracting coefficients of null model
summary(nullmodel)
tidy(nullmodel, conf.int = TRUE)

# Computing standardized beta coefficients
nullmodel_standardized <- lm.beta(nullmodel)
coef(nullmodel_standardized)
```

## Extracting specific model test statistics of null model and putting them into a table

```{r}
adjusted_r2_nullmodel <- glance(nullmodel) %>% pull(adj.r.squared)
f_statistic_nullmodel <- glance(nullmodel) %>% pull(statistic)
p_value_nullmodel <- glance(nullmodel) %>% pull(p.value)
df_nullmodel <- glance(nullmodel) %>% pull(df)
AIC_nullmodel <- glance(nullmodel) %>% pull(AIC)

model_stats_nullmodel <- tibble(
  Statistic = c("Adjusted R-squared", "F-statistic", "p-value", "Degrees of Freedom", "AIC"),
  Value = c(adjusted_r2_nullmodel, f_statistic_nullmodel, p_value_nullmodel, df_nullmodel, AIC_nullmodel))

print(model_stats_nullmodel)
```

## Extracting coefficients of null model and putting them into a table

```{r}
standardized_coefficients_nullmodel <- (coef(nullmodel_standardized))[-1]
  
coeff_extracted_nullmodel <- tidy(nullmodel, conf.int = TRUE) %>%
  select(term, estimate, conf.low, conf.high, p.value) %>%
  mutate(standardized = c(NA, standardized_coefficients_nullmodel))

print(coeff_extracted_nullmodel)
```

## Checking the model

### Cook's distance for null model and checking for influential outliers (Cook's distance > 1)

```{r}
cooks_distance_nullmodel <- cooks.distance(nullmodel)
influential_outliers_nullmodel <- which(cooks_distance_nullmodel > 1)
influential_outliers_nullmodel

# There are no influential outliers according to the test.
```

### Q-Q plot for residual normality check

```{r}
autoplot(nullmodel, which = 2)

# The plot shows that residuals are not normally distributed.

# Computing leverage values and checking leverage for specific observations that deviate from the Q-Q plot line
leverage_values <- hatvalues(nullmodel)
leverage_values[c(3541, 2399, 4201)]

## Viewing observations that might be influential
animal_rescues_interest[3541, ]
animal_rescues_interest[2399, ]
animal_rescues_interest[4201, ]
# Horses and a cat with high rescue costs.
```

### Independence of residuals (Durbin-Watson test)

```{r}
dwtest(nullmodel)

# Positive autocorrelation between residuals.
```

### Residuals vs. fitted plot to check linearity and homoskedasticity

```{r}
autoplot(nullmodel, which = 1)

# Linearity is not applicable because the only predictor is a factor.
# There are outlier residuals.
# Homoskedasticity is not violated.
```

Due to assumption violations, I will try log-transforming the outcome variable (incident_notional_cost), and check whether the model improves.

##  Fitting null model with log-transformed outcome variable

```{r}
animal_rescues_interest <- animal_rescues_interest %>%
  mutate(log_incident_notional_cost = log(incident_notional_cost + 1))

nullmodel_log <- lm(log_incident_notional_cost ~ domestic_wild, data = animal_rescues_interest)
```

## Extracting statistics and coefficients of log-transformed null model, computing standardized coefficients

```{r}
# Model statistics
glance(nullmodel_log)

#Coefficients
summary(nullmodel_log)
tidy(nullmodel_log, conf.int = TRUE)

# Computing standardized beta coefficients
nullmodel_log_standardized <- lm.beta(nullmodel_log)
coef(nullmodel_log_standardized)
```

## Extracting specific model test statistics of log-transformed null model and putting them into a table

```{r}
adjusted_r2_nullmodel_log <- glance(nullmodel_log) %>% pull(adj.r.squared)
f_statistic_nullmodel_log <- glance(nullmodel_log) %>% pull(statistic)
p_value_nullmodel_log <- glance(nullmodel_log) %>% pull(p.value)
df_nullmodel_log <- glance(nullmodel_log) %>% pull(df)
AIC_nullmodel_log <- glance(nullmodel_log) %>% pull(AIC)

model_stats_nullmodel_log <- tibble(
  Statistic = c("Adjusted R-squared", "F-statistic", "p-value", "Degrees of Freedom", "AIC"),
  Value = c(adjusted_r2_nullmodel_log, f_statistic_nullmodel_log, p_value_nullmodel_log, df_nullmodel_log, AIC_nullmodel_log))

print(model_stats_nullmodel_log)
```

## Extracting coefficients of log-transformed null model and putting them into a table

```{r}
standardized_coefficients_nullmodel_log <- (coef(nullmodel_log_standardized))[-1]
  
coeff_extracted_nullmodel_log <- tidy(nullmodel_log, conf.int = TRUE) %>%
  select(term, estimate, conf.low, conf.high, p.value) %>%
  mutate(standardized = c(NA, standardized_coefficients_nullmodel_log))

print(coeff_extracted_nullmodel_log)
```

## Checking the model

### Cook's distance for log-transformed null model and checking for influential outliers (Cook's distance > 1)

```{r}
cooks_distance_nullmodel_log <- cooks.distance(nullmodel_log)
influential_outliers_nullmodel_log <- which(cooks_distance_nullmodel_log > 1)
influential_outliers_nullmodel_log

# There are no influential outliers according to the test.
```

### Q-Q plot for residual normality check

```{r}
autoplot(nullmodel_log, which = 2)

# The plot shows that residuals are still not normally distributed.

# Computing leverage values and checking leverage for specific observations that deviate from the Q-Q plot line
leverage_values <- hatvalues(nullmodel_log)
leverage_values[c(5518, 2399, 420)]

## Viewing observations that might be influential
animal_rescues_interest[5518, ]
animal_rescues_interest[2399, ]
animal_rescues_interest[4201, ]
# Horses and a dog with no rescue cost.
```

### Independence of residuals (Durbin-Watson test)

```{r}
dwtest(nullmodel_log)

# Positive autocorrelation between residuals.
```


### Residuals vs. fitted plot to check linearity and homoskedasticity

```{r}
autoplot(nullmodel_log, which = 1)

# Linearity is not applicable because the only predictor is a factor.
# There are outlier residuals.
# Homoskedasticity is not violated.
```

The model didn't get much better when it comes to assumptions. I will build the complex model and see what happens there.

# üêæ Building complex model üêæ

In this section I will investigate what other factors influence rescue cost with a more complex linear regression model.

Outcome: incident_notional_cost

In the more complex model, I will include the following **predictors**:  
- day_or_night: computed from date_time_of_call (0: day, 1: night);  
- pump_count: number of trucks needed for the rescue;    
- pump_hours_total: length of rescue operation;  
- domestic_wild: computed from animal_group_parent (0: domestic; 1: wild);  
- borough_inner_outer: computed from borough (0: inner; 1: outer).

## Fitting complex model

```{r}
complexmodel <- lm(incident_notional_cost ~ day_or_night + pump_count + pump_hours_total + domestic_wild + borough_inner_outer, data = animal_rescues_interest)
```

## Extracting statistics and coefficients of complex model, computing standardized coefficients

```{r}
# Model statistics
glance(complexmodel)

#Coefficients
summary(complexmodel)
tidy(complexmodel, conf.int = TRUE)

# Computing standardized beta coefficients
complexmodel_standardized <- lm.beta(complexmodel)
coef(complexmodel_standardized)
```

## Extracting specific model test statistics of complex model and putting them into a table

```{r}
adjusted_r2_complexmodel <- glance(complexmodel) %>% pull(adj.r.squared)
f_statistic_complexmodel <- glance(complexmodel) %>% pull(statistic)
p_value_complexmodel <- glance(complexmodel) %>% pull(p.value)
df_complexmodel <- glance(complexmodel) %>% pull(df)
AIC_complexmodel <- glance(complexmodel) %>% pull(AIC)

model_stats_complexmodel <- tibble(
  Statistic = c("Adjusted R-squared", "F-statistic", "p-value", "Degrees of Freedom", "AIC"),
  Value = c(adjusted_r2_complexmodel, f_statistic_complexmodel, p_value_complexmodel, df_complexmodel, AIC_complexmodel))

print(model_stats_complexmodel)
```

## Extracting coefficients of complex model and putting them into a table

```{r}
standardized_coefficients_complexmodel <- (coef(complexmodel_standardized))[-1]
  
coeff_extracted_complexmodel <- tidy(complexmodel, conf.int = TRUE) %>%
  select(term, estimate, conf.low, conf.high, p.value) %>%
  mutate(standardized = c(NA, standardized_coefficients_complexmodel))

print(coeff_extracted_complexmodel)
```

## Checking the model

### Cook's distance for complex model and checking for influential outliers (Cook's distance > 1)

```{r}
cooks_distance_complexmodel <- cooks.distance(complexmodel)
influential_outliers_complexmodel <- which(cooks_distance_complexmodel > 1)
influential_outliers_complexmodel

# There are no influential outliers according to the test.
```

### Q-Q plot for residual normality check

```{r}
autoplot(complexmodel, which = 2)

# The plot shows that residuals are not normally distributed.

# Computing leverage values and checking leverage for specific observations that deviate from the Q-Q plot line
leverage_values <- hatvalues(complexmodel)
leverage_values[c(1391, 6751, 4201)]

## Viewing observations that might be influential
animal_rescues_interest[1391, ]
animal_rescues_interest[6751, ]
animal_rescues_interest[4201, ]
### A horse, a deer and a cat with high rescue costs.
```

### Residuals vs. fitted plot to check linearity and homoskedasticity

```{r}
autoplot(complexmodel, which = 1)

# The bumpy line suggests that linearity is violated. 
# The fanning pattern suggests that homoskedasticity is also violated.
```

### Independence of residuals (Durbin-Watson test)

```{r}
dwtest(complexmodel)

# Positive autocorrelation between residuals.
```

### Calculating VIF values for complex model

```{r}
vif(complexmodel)

# VIF < 5, so these are okay
```

The assumption checks still don't look nice, so I will try the log-transformation with the complex model too.

## Fitting log-transformed complex model

```{r}
complexmodel_log <- lm(log_incident_notional_cost ~ day_or_night + pump_count + pump_hours_total + domestic_wild + borough_inner_outer, data = animal_rescues_interest)
```

## Extracting statistics and coefficients of log-transformed complex model, computing standardized coefficients

```{r}
# Model statistics
glance(complexmodel_log)

#Coefficients
summary(complexmodel_log)
tidy(complexmodel_log, conf.int = TRUE)

# Computing standardized beta coefficients
complexmodel_log_standardized <- lm.beta(complexmodel_log)
coef(complexmodel_log_standardized)
```

## Extracting specific model test statistics of log-transformed complex model and putting them into a table

```{r}
adjusted_r2_complexmodel_log <- glance(complexmodel_log) %>% pull(adj.r.squared)
f_statistic_complexmodel_log <- glance(complexmodel_log) %>% pull(statistic)
p_value_complexmodel_log <- glance(complexmodel) %>% pull(p.value)
df_complexmodel_log <- glance(complexmodel_log) %>% pull(df)
AIC_complexmodel_log <- glance(complexmodel_log) %>% pull(AIC)

model_stats_complexmodel_log <- tibble(
  Statistic = c("Adjusted R-squared", "F-statistic", "p-value", "Degrees of Freedom", "AIC"),
  Value = c(adjusted_r2_complexmodel_log, f_statistic_complexmodel_log, p_value_complexmodel_log, df_complexmodel_log, AIC_complexmodel_log))

print(model_stats_complexmodel_log)
```

## Extracting coefficients of log-transformed complex model and putting them into a table

```{r}
standardized_coefficients_complexmodel_log <- (coef(complexmodel_log_standardized))[-1]
  
coeff_extracted_complexmodel_log <- tidy(complexmodel_log, conf.int = TRUE) %>%
  select(term, estimate, conf.low, conf.high, p.value) %>%
  mutate(standardized = c(NA, standardized_coefficients_complexmodel_log))

print(coeff_extracted_complexmodel_log)
```

## Checking the model

### Cook's distance for log-transformed complex model and checking for influential outliers (Cook's distance > 1)

```{r}
cooks_distance_complexmodel_log <- cooks.distance(complexmodel_log)
influential_outliers_complexmodel_log <- which(cooks_distance_complexmodel_log > 1)
influential_outliers_complexmodel_log

# We have already seen these animals before, they had high rescue costs.
```

### Q-Q plot for residual normality check

```{r}
autoplot(complexmodel_log, which = 2)

# The plot shows that residuals are still not normally distributed.

# Computing leverage values and checking leverage for specific observations that deviate from the Q-Q plot line
leverage_values <- hatvalues(complexmodel_log)
leverage_values[c(5518, 2399, 4201)]

# Viewing observations that might be influential
animal_rescues_interest[5518, ]
animal_rescues_interest[2399, ]
animal_rescues_interest[4201, ]
# High rescue costs or no cost.
```

### Residuals vs. fitted plot to check linearity and homoskedasticity

```{r}
autoplot(complexmodel_log, which = 1)

# The line is somewhat more linear but it still has a little bump. The outlier values seem to drag the line downwards.
```

### Independence of residuals (Durbin-Watson test)

```{r}
dwtest(complexmodel_log)

# Positive autocorrelation between residuals.
```

### Calculating VIF values for log-transformed complex model

```{r}
vif(complexmodel_log)

# VIF < 5, so these are okay
```

Still not perfect (maybe some improvement compared to the original complex model). I will compare both the original, both the log transformed models' performance.

# üêæ Model comparison üêæ

## Comparing the original null model with the original complex model

### Comparing model stats (AIC, F-statistic, p-value)

```{r}
# Null model stats
model_stats_nullmodel

# Complex model stats
model_stats_complexmodel

# Comparing AIC-values: the complex model has lower AIC (better)
AIC_nullmodel
AIC_complexmodel

# Comparing F-values of the models: the complex model has higher F-statistic (better)
f_statistic_nullmodel
f_statistic_complexmodel

# Comparing p-values of the models: the complex model has lower p-value (better)
p_value_nullmodel
p_value_complexmodel
```

The complex model seems to have better performance, because it has lower AIC and p-value and higher F-statistic.

### Coefficient interpretation

```{r}
coeff_extracted_nullmodel
coeff_extracted_complexmodel
```

In the null model, the animal type was not a significant predictor of rescue cost.

In the more complex model:  
- day_or_night: significant predicor (night rescues more expensive)  
- pump_count: significant preditor (more pumps - less expensive)  
- pump_hours_total: significant predictor (longer rescue - more expensive)  
- domestic_wild: significant predictor (wild animals - more expensive)  
- borough_inner_outer: not significant (outer borough - cheaper)  

Compared to the correlations, by controlling for other factors as well, the picture became more detailed. For example, in the regression model, more pumps lead to smaller costs. That might be because the model also controls for the length of the rescue, which might be decreased if more pumps are working. Also, at night, maybe fewer pumps are available. In the regression, wild animal rescues and outer borough rescues were also associated with higher costs (the correlations were either weak or insignificant in these cases).

My hypothesis (rescuing non-domestic animals is more expensive) seem to be supported.

## Comparing the log-transformed null model with the log-transformed complex model

### Comparing model stats (AIC, F-statistic, p-value)

```{r}
# Null model stats
model_stats_nullmodel_log

# Complex model stats
model_stats_complexmodel_log

# Comparing AIC-values: the complex model has lower AIC (better)
# Both are better than the original models without log-transformation.
AIC_nullmodel_log
AIC_complexmodel_log

# Comparing F-values of the models: the complex model has higher F-statistic (better)
# The original complex model has higher F-value
f_statistic_nullmodel_log
f_statistic_complexmodel_log

# Comparing p-values of the models: the complex model has lower p-value (better)
# Log-transformed null model has lower p-value than original, the complex models are both p = 0
p_value_nullmodel_log
p_value_complexmodel_log
```

The complex model seems to have better performance, because it has lower AIC and p-value and higher F-statistic. Compared to the original models, the log-transformed models don't outperform them definitely.

### Coefficient interpretation

```{r}
coeff_extracted_nullmodel_log
coeff_extracted_complexmodel_log
```

In the null model, the animal type was not a significant predictor of rescue cost.

In the more complex model:  
- day_or_night: not significant  
- pump_count: significant predictor (more pumps - less expensive)  
- pump_hours_total: significant predictor (longer rescue - more expensive)  
- domestic_wild: significant predictor (wild animals - more expensive)  
- borough_inner_outer: not significant  

The coefficients' results are similar to the results of the original models.

# üêæ Closing remarks üêæ

I used OpenAI‚Äôs ChatGPT throughout this project for brainstorming ideas, generating code suggestions, and debugging. It also helped me to interpret the results. I always requested explanations for the generated code and tested it to make sure that it worked correctly and aligned with my analysis goals.

Thank you for reading my report!

![*Photo by George Bonev on Unsplash*](https://images.unsplash.com/photo-1498579687545-d5a4fffb0a9e?q=80&w=2070&auto=format&fit=crop&ixlib=rb-4.0.3&ixid=M3wxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8fA%3D%3D)
